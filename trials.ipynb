{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install pinecone-client\n",
    "# !pip install pinecone\n",
    "# !pip install sentence_transformers\n",
    "!pip install huggingface_hub==0.25.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_6K37fx_4ojcVFjUNuemDqFEp8bs3oGYu2gX8XeL6ACbjGqtFwciSWqrFu7hXaFsiHqWqQD\"\n",
    "#PINECONE_API_ENV = \"us-east1-aws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Set your Pinecone API key\n",
    "PINECONE_API_KEY = \"pcsk_6K37fx_4ojcVFjUNuemDqFEp8bs3oGYu2gX8XeL6ACbjGqtFwciSWqrFu7hXaFsiHqWqQD\"\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=\"us-east1-aws\")\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Create an index with the correct dimension (384)\n",
    "pinecone.create_index(index_name, dimension=384, metric=\"cosine\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Use HuggingFaceEmbeddings to create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Creating Embeddings for each of the text chunks and storing\n",
    "text_chunks = [\"your text chunk 1\", \"your text chunk 2\", ...]  # Replace with your actual text chunks\n",
    "docsearch = Pinecone.from_texts(\n",
    "    texts=[t for t in text_chunks],\n",
    "    embeddings=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query_text = \"your query text\"\n",
    "query_embeddings = embeddings.encode([query_text])\n",
    "result = index.query(queries=query_embeddings, top_k=5)\n",
    "print(result)\n",
    "\n",
    "# Optional: Delete the index\n",
    "pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the pdf\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vdo\n",
    "#Initializing the Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "#Creating Embeddings for Each of the Text Chunks and storing\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pinecone\n",
    "\n",
    "# Set your Pinecone API key\n",
    "PINECONE_API_KEY = \"your_actual_pinecone_api_key\"\n",
    "PINECONE_API_ENV = \"us-east1-aws\"  # Ensure this matches your Pinecone environment\n",
    "\n",
    "# Create an instance of the Pinecone client\n",
    "client = pinecone.Client()\n",
    "\n",
    "# Initialize Pinecone with the correct API key and environment\n",
    "client.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "\n",
    "# Create an index with the correct dimension (384) if it doesn't already exist\n",
    "index_name = \"medical-chatbot\"\n",
    "if not client.list_indexes().get('names', []):\n",
    "    client.create_index(\n",
    "        name=index_name, \n",
    "        dimension=384, \n",
    "        metric='cosine',\n",
    "        spec=pinecone.ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = client.index(index_name)\n",
    "\n",
    "# Use HuggingFaceEmbeddings to create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Creating Embeddings for each of the text chunks and storing\n",
    "text_chunks = [\"your text chunk 1\", \"your text chunk 2\", ...]  # Replace with your actual text chunks\n",
    "docsearch = Pinecone.from_texts(\n",
    "    texts=[t for t in text_chunks],\n",
    "    embeddings=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query_text = \"your query text\"\n",
    "query_embeddings = embeddings.encode([query_text])\n",
    "result = index.query(queries=query_embeddings, top_k=5)\n",
    "print(result)\n",
    "\n",
    "# Optional: Delete the index\n",
    "client.delete_index(index_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
